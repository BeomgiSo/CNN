{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32e55f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF 2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "print(\"TF\",tf.__version__)\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ab86dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model into KerasLayer\n",
    "model_url = \"https://tfhub.dev/google/bit/m-r50x1/1\"\n",
    "module = hub.KerasLayer(model_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78e34c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'dataset'\n",
    "train_dir = os.path.join(data_dir,\"data\")\n",
    "train_fnames = os.listdir(train_dir)\n",
    "NUM_CLASSES = len(train_fnames)\n",
    "print(NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47c9fef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20909 images belonging to 127 classes.\n",
      "Found 5172 images belonging to 127 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255.,\n",
    "                                  validation_split=0.2)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(train_dir,\n",
    "                                              target_size=(224,224),\n",
    "                                              batch_size=32,\n",
    "                                              class_mode=\"categorical\",\n",
    "                                              shuffle = True,\n",
    "                                              subset='training')\n",
    "validation_data = train_datagen.flow_from_directory(train_dir,\n",
    "                                              target_size=(224,224),\n",
    "                                              batch_size=32,\n",
    "                                              class_mode=\"categorical\",\n",
    "                                              shuffle = True,\n",
    "                                              subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16c46674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiT model 구성하기\n",
    "\n",
    "class MyBiTModel(tf.keras.Model):\n",
    "  \"\"\"BiT with a new head.\"\"\"\n",
    "\n",
    "  def __init__(self, num_classes, module):\n",
    "    super().__init__()\n",
    "\n",
    "    self.num_classes = num_classes\n",
    "    self.head = tf.keras.layers.Dense(num_classes, kernel_initializer='zeros')\n",
    "    self.bit_model = module\n",
    "  \n",
    "  def call(self, images):\n",
    "    # No need to cut head off since we are using feature extractor model\n",
    "    bit_embedding = self.bit_model(images)\n",
    "    return self.head(bit_embedding)\n",
    "\n",
    "model = MyBiTModel(num_classes=NUM_CLASSES, module=module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3a8e1d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_bi_t_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               multiple                  260223    \n",
      "                                                                 \n",
      " keras_layer (KerasLayer)    multiple                  23500352  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,760,575\n",
      "Trainable params: 260,223\n",
      "Non-trainable params: 23,500,352\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1710e560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.preprocessing.image.DirectoryIterator object at 0x000001A7DE562CA0>\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4001c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer = Adam(1e-3),\n",
    "             loss = \"categorical_crossentropy\",\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8750f1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 951525658347962674\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5738397696\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 13974684223565143559\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:2b:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1001a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "654/654 [==============================] - 100s 150ms/step - loss: nan - accuracy: 0.0092 - val_loss: nan - val_accuracy: 0.0091\n",
      "Epoch 2/50\n",
      "654/654 [==============================] - 97s 148ms/step - loss: nan - accuracy: 0.0092 - val_loss: nan - val_accuracy: 0.0091\n",
      "Epoch 3/50\n",
      "654/654 [==============================] - 98s 150ms/step - loss: nan - accuracy: 0.0092 - val_loss: nan - val_accuracy: 0.0091\n",
      "Epoch 4/50\n",
      "654/654 [==============================] - 102s 156ms/step - loss: nan - accuracy: 0.0092 - val_loss: nan - val_accuracy: 0.0091\n",
      "Epoch 5/50\n",
      "654/654 [==============================] - 101s 154ms/step - loss: nan - accuracy: 0.0092 - val_loss: nan - val_accuracy: 0.0091\n",
      "Epoch 6/50\n",
      "654/654 [==============================] - 98s 150ms/step - loss: nan - accuracy: 0.0092 - val_loss: nan - val_accuracy: 0.0091\n",
      "Epoch 7/50\n",
      "654/654 [==============================] - 111s 170ms/step - loss: nan - accuracy: 0.0092 - val_loss: nan - val_accuracy: 0.0091\n",
      "Epoch 8/50\n",
      "436/654 [===================>..........] - ETA: 26s - loss: nan - accuracy: 0.0087"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data,\n",
    "                    epochs = 50,\n",
    "                    batch_size=32,\n",
    "                    validation_data = validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c301098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "his_dict = history.history\n",
    "loss = his_dict['loss']\n",
    "val_loss = his_dict['val_loss'] \n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "\n",
    "# 훈련 및 검증 손실 그리기\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.plot(epochs, loss, color = 'blue', label = 'train_loss')\n",
    "ax1.plot(epochs, val_loss, color = 'orange', label = 'val_loss')\n",
    "ax1.set_title('train and val loss')\n",
    "ax1.set_xlabel('epochs')\n",
    "ax1.set_ylabel('loss')\n",
    "ax1.legend()\n",
    "\n",
    "acc = his_dict['accuracy']\n",
    "val_acc = his_dict['val_accuracy']\n",
    "\n",
    "# 훈련 및 검증 정확도 그리기\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.plot(epochs, acc, color = 'blue', label = 'train_acc')\n",
    "ax2.plot(epochs, val_acc, color = 'orange', label = 'val_acc')\n",
    "ax2.set_title('train and val acc')\n",
    "ax2.set_xlabel('epochs')\n",
    "ax2.set_ylabel('acc')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project3",
   "language": "python",
   "name": "project3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
