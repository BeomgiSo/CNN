{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# Set the random seeds\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1' \n",
    "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
    "tf.random.set_seed(hash(\"by removing stochasticity\") % 2**32 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbeomgiso\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train:  (10000, 32, 32, 3)\n",
      "Shape of y_train:  (10000, 1)\n",
      "Shape of x_test:  (10000, 32, 32, 3)\n",
      "Shape of y_test:  (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Subsetting train data and normalizing to [0., 1.]\n",
    "x_train, x_test = x_train[::5] / 255., x_test / 255.\n",
    "y_train = y_train[::5]\n",
    "\n",
    "CLASS_NAMES = [\"airplane\", \"automobile\", \"bird\", \"cat\",\n",
    "               \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "print('Shape of x_train: ', x_train.shape)\n",
    "print('Shape of y_train: ', y_train.shape)\n",
    "print('Shape of x_test: ', x_test.shape)\n",
    "print('Shape of y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model():\n",
    "  inputs = keras.layers.Input(shape=(32, 32, 3))\n",
    "\n",
    "  x = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(inputs)\n",
    "  x = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(x)\n",
    "  x = keras.layers.MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "  x = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(x)\n",
    "  x = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(x)\n",
    "\n",
    "  x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "  x = keras.layers.Dense(128, activation='relu')(x)\n",
    "  x = keras.layers.Dense(32, activation='relu')(x)\n",
    "  \n",
    "  outputs = keras.layers.Dense(len(CLASS_NAMES), activation='softmax')(x)\n",
    "\n",
    "  return keras.models.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\beomgi_so\\Desktop\\CNN_project\\CNN\\wandb\\run-20220614_231317-1fd449dw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/beomgiso/my-keras-integration/runs/1fd449dw\" target=\"_blank\">fast-snow-6</a></strong> to <a href=\"https://wandb.ai/beomgiso/my-keras-integration\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 37,322\n",
      "Trainable params: 37,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialize wandb with your project name\n",
    "run = wandb.init(project='my-keras-integration',\n",
    "                 config={  # and include hyperparameters and metadata\n",
    "                     \"learning_rate\": 0.005,\n",
    "                     \"epochs\": 20,\n",
    "                     \"batch_size\": 64,\n",
    "                     \"loss_function\": \"sparse_categorical_crossentropy\",\n",
    "                     \"architecture\": \"CNN\",\n",
    "                     \"dataset\": \"CIFAR-10\"\n",
    "                 })\n",
    "config = wandb.config  # We'll use this to configure our experiment\n",
    "\n",
    "# Initialize model like you usually do.\n",
    "tf.keras.backend.clear_session()\n",
    "model = Model()\n",
    "model.summary()\n",
    "\n",
    "# Compile model like you usually do.\n",
    "# Notice that we use config, so our metadata matches what gets executed\n",
    "optimizer = tf.keras.optimizers.Adam(config.learning_rate) \n",
    "model.compile(optimizer, config.loss_function, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "# We train with our beloved model.fit\n",
    "# Notice WandbCallback is used as a regular callback\n",
    "# We again use config\n",
    "_ = model.fit(x_train, y_train,\n",
    "          epochs=config.epochs, \n",
    "          batch_size=config.batch_size,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print('Test Error Rate: ', round((1 - accuracy) * 100, 2))\n",
    "\n",
    "# With wandb.log, we can easily pass in metrics as key-value pairs.\n",
    "wandb.log({'Test Error Rate': round((1 - accuracy) * 100, 2)})\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize wandb with your project name\n",
    "run = wandb.init(project='my-keras-integration',\n",
    "                 config={  # and include hyperparameters and metadata\n",
    "                     \"learning_rate\": 0.001,\n",
    "                     \"epochs\": 5,\n",
    "                     \"batch_size\": 32,\n",
    "                     \"loss_function\": \"sparse_categorical_crossentropy\",\n",
    "                     \"architecture\": \"CNN\",\n",
    "                     \"dataset\": \"CIFAR-10\"\n",
    "                 })\n",
    "config = wandb.config  # We'll use this to configure our experiment\n",
    "\n",
    "# Initialize model like you usually do.\n",
    "tf.keras.backend.clear_session()\n",
    "model = Model()\n",
    "model.summary()\n",
    "\n",
    "# Compile model like you usually do.\n",
    "optimizer = tf.keras.optimizers.Adam(config.learning_rate) \n",
    "model.compile(optimizer, config.loss_function, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We focus on a subset of images, since this is for human review\n",
    "val_images, val_labels = x_test[:32], y_test[:32]\n",
    "\n",
    "# Our beloved model.fit returns\n",
    "# By passing arguments to WandbCallback, we change its behavior\n",
    "_ = model.fit(x_train, y_train,\n",
    "              epochs=config.epochs, \n",
    "              batch_size=config.batch_size,\n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[WandbCallback(data_type='image', \n",
    "                                       validation_data=(val_images, val_labels), \n",
    "                                       labels=CLASS_NAMES)])\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project3",
   "language": "python",
   "name": "project3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
